{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Nov  4 17:10:20 2020\n",
    "\n",
    "@author: Tagore pothuneedi \n",
    "@Used code: PJ\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt #to plot required plots\n",
    "from skimage.transform import resize #to resize image \n",
    "from skimage.util import pad #to pad values in numpy array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import os #to get paths of images\n",
    "import cv2 #to read images\n",
    "from sklearn.decomposition import PCA\n",
    "scores={}\n",
    "\n",
    "\n",
    "#function used to show the image\n",
    "def show_image(image_path,title='Image',cmap_type='gray'):\n",
    "    img_grey = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    plt.imshow(img_grey,cmap=cmap_type)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# function to get all file paths from provided directory\n",
    "def get_list_of_files(dir_path):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    files = os.listdir(dir_path)\n",
    "    all_files = list()\n",
    "    # Iterate over all the entries\n",
    "    for file in files:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dir_path, file)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            all_files = all_files + get_list_of_files(fullPath)\n",
    "        else:\n",
    "            all_files.append(fullPath)\n",
    "                \n",
    "    return all_files\n",
    "\n",
    "#function to get folder names from provided path : folder name is later used as target label\n",
    "def get_folder_name_list(dir_path):\n",
    "   base_path_folder_list=[]\n",
    "   for entry in os.listdir(dir_path):\n",
    "       if os.path.isdir(os.path.join(dir_path, entry)):\n",
    "           base_path_folder_list.append(entry) \n",
    "   return base_path_folder_list\n",
    "\n",
    "#white padding : padwithone black padding:pad with zero\n",
    "#used in preprocessing of image, for adding 2 pixel border from all sides\n",
    "def padwithzeros(vector, pad_width, iaxis, kwargs):\n",
    "    vector[:pad_width[0]] = 0\n",
    "    vector[-pad_width[1]:] = 0\n",
    "    return vector\n",
    "\n",
    "def pre_process_image(img_path):\n",
    "    #show_image(img_path,'greyimg')\n",
    "    img_grey = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "        \n",
    "    # define a threshold, 128 is the middle of black and white in grey scale\n",
    "    thresh = 128\n",
    "    \n",
    "    # threshold the image\n",
    "    img_binary = cv2.threshold(img_grey, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    #invert the binary image to get clear image\n",
    "    inverted_binary_image =  cv2.bitwise_not(img_binary)\n",
    "    fimg = np.where(inverted_binary_image>0,1,inverted_binary_image)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # can be used when image is not 32 * 32 pixel \n",
    "    resized_img = resize(inverted_binary_image,(32,32),anti_aliasing=False) # second parameter : scale here 2 double the size\n",
    "    resized_img_with_padding = pad(resized_img,2,padwithzeros)\n",
    "    fimg = np.where(resized_img_with_padding>0,1,resized_img_with_padding)\n",
    "    '''\n",
    "    #normalized_fimg = fimg / np.linalg.norm(fimg)\n",
    "    normalized_fimg = fimg \n",
    "    \n",
    "    #filters\n",
    "    #sobelx = cv2.Sobel(fimg,cv2.CV_64F,1,0,ksize=5)\n",
    "    #sobely = cv2.Sobel(fimg,cv2.CV_64F,0,1,ksize=5)\n",
    "    #laplacian = cv2.Laplacian(fimg,cv2.CV_64F)\n",
    "    \n",
    "    return normalized_fimg.flatten()\n",
    "\n",
    "#get list of preprocessed images\n",
    "def load_images_list(img_paths):\n",
    "    images=[]\n",
    "    for img_path in img_paths:\n",
    "        fimg = pre_process_image(img_path)\n",
    "        images.append(fimg)\n",
    "    return images\n",
    "\n",
    "# base path for dataset\n",
    "base_path=r\"C:\\Users\\tagor\\Desktop\\ml\\DevanagariHandwrittenCharacterDataset\\Train\"\n",
    "\n",
    "\n",
    "\n",
    "#base_path_folder_list = get_folder_name_list(base_path)    \n",
    "#print(base_path_folder_list)\n",
    "\n",
    "\n",
    "#base_path_folder_list=['character_1_ka','character_2_kha','character_3_ga','character_4_gha','character_5_kna']\n",
    "base_path_folder_list=['digit_0', 'digit_1', 'digit_2', 'digit_3', 'digit_4', 'digit_5', 'digit_6', 'digit_7', 'digit_8', 'digit_9']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "i=0\n",
    "for folder_name in base_path_folder_list:\n",
    "    img_path=base_path+'/'+folder_name+'/'\n",
    "    images_path_list = get_list_of_files(img_path)\n",
    "    images_flattened = load_images_list(images_path_list)\n",
    "    df_images = pd.DataFrame(images_flattened)\n",
    "    df_images['label'] = i\n",
    "    i+=1\n",
    "    \n",
    "    ##subdivide\n",
    "    ##astract\n",
    "    \n",
    "    df=df.append(df_images,ignore_index=True)\n",
    "    \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#shuffle records in df\n",
    "df = df.sample(frac = 1) \n",
    "X=df.iloc[:,df.columns != 'label']\n",
    "y=df['label']\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=.2,random_state=1111,stratify=y)\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "#target_names=['character_1_ka','character_2_kha','character_3_ga']\n",
    "target_names=base_path_folder_list.copy()\n",
    "\n",
    "\n",
    "#testing random image\n",
    "test_base_path = r'C:\\Users\\tagor\\Desktop\\ml\\DevanagariHandwrittenCharacterDataset\\Test'\n",
    "test_img_path=test_base_path+'digit_7/5771.png'\n",
    "\n",
    "\n",
    "def test_char(img_path):\n",
    "    test_img = pre_process_image(img_path)\n",
    "    test_img=test_img.reshape(1,-1)\n",
    "    print(\"rfc: {0}\".format(rfc.predict(test_img)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################\n",
    "#CNN \n",
    "##################\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13600, 1024), (17000, 1024))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (13600, 32, 32, 1)\n",
      "13600 train samples\n",
      "3400 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32,32\n",
    "\n",
    "# the data, split between train and test sets\n",
    "\n",
    "x_train = np.asarray(X_train).reshape(13600,32,32,1)\n",
    "x_test = np.asarray(X_test).reshape(3400,32,32,1)\n",
    "\n",
    "#x_train = X_train\n",
    "#x_test = X_test\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import sigmoid,tanh,exp\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "\n",
    "def swish(x, beta = 2):\n",
    "    return (x * sigmoid(beta * x))\n",
    "def param_tanh(x):\n",
    "    return x*tanh(x)\n",
    "def relu_moid(x):\n",
    "    #if x > 0.0:\n",
    "    #    return x\n",
    "    #else:\n",
    "    #    return 1/1+exp(-x)\n",
    "\n",
    "    return K.switch(x>0,x,sigmoid(x))\n",
    "\n",
    "def param_sigmoid(x):\n",
    "    return x/(1+exp(-x))\n",
    "    #print(x)\n",
    "    \n",
    "    \n",
    "\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "get_custom_objects().update({'param_tanh': Activation(param_tanh)})\n",
    "get_custom_objects().update({'relu_moid': Activation(relu_moid)})\n",
    "get_custom_objects().update({'param_sigmoid': Activation(param_sigmoid)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu_moid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu_moid',input_shape=(32,32,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu_moid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu_moid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3400, 32, 32, 1), (3400, 10), (13600, 32, 32, 1), (13600, 10))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimizer=keras.optimizers.Adadelta(),\n",
    "x_test.shape,y_test.shape,x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "107/107 [==============================] - 16s 151ms/step - loss: 2.5880 - accuracy: 0.1013 - val_loss: 2.3025 - val_accuracy: 0.1000\n",
      "Epoch 2/12\n",
      "107/107 [==============================] - 17s 155ms/step - loss: 2.3022 - accuracy: 0.1002 - val_loss: 2.3023 - val_accuracy: 0.1000\n",
      "Epoch 3/12\n",
      "107/107 [==============================] - 17s 156ms/step - loss: 2.3035 - accuracy: 0.1070 - val_loss: 2.3024 - val_accuracy: 0.1009\n",
      "Epoch 4/12\n",
      "107/107 [==============================] - 17s 156ms/step - loss: 2.2972 - accuracy: 0.1027 - val_loss: 2.2413 - val_accuracy: 0.1012\n",
      "Epoch 5/12\n",
      "107/107 [==============================] - 17s 156ms/step - loss: 2.0672 - accuracy: 0.1784 - val_loss: 1.1208 - val_accuracy: 0.7744\n",
      "Epoch 6/12\n",
      "107/107 [==============================] - 17s 155ms/step - loss: 1.0316 - accuracy: 0.6097 - val_loss: 0.3536 - val_accuracy: 0.8956\n",
      "Epoch 7/12\n",
      "107/107 [==============================] - 17s 155ms/step - loss: 0.6095 - accuracy: 0.7826 - val_loss: 0.2111 - val_accuracy: 0.9421\n",
      "Epoch 8/12\n",
      "107/107 [==============================] - 17s 157ms/step - loss: 0.3483 - accuracy: 0.8811 - val_loss: 0.1206 - val_accuracy: 0.9644\n",
      "Epoch 9/12\n",
      "107/107 [==============================] - 17s 155ms/step - loss: 0.2474 - accuracy: 0.9168 - val_loss: 0.0968 - val_accuracy: 0.9724\n",
      "Epoch 10/12\n",
      "107/107 [==============================] - 17s 155ms/step - loss: 0.1906 - accuracy: 0.9374 - val_loss: 0.0830 - val_accuracy: 0.9765\n",
      "Epoch 11/12\n",
      "107/107 [==============================] - 17s 156ms/step - loss: 0.1500 - accuracy: 0.9533 - val_loss: 0.0737 - val_accuracy: 0.9759\n",
      "Epoch 12/12\n",
      "107/107 [==============================] - 17s 160ms/step - loss: 0.1149 - accuracy: 0.9613 - val_loss: 0.0670 - val_accuracy: 0.9812\n",
      "Test loss: 0.06695754826068878\n",
      "Test accuracy: 0.981176495552063\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "scores['Relu_moid']=score[1]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# param_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='param_tanh',input_shape=(32,32,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='param_tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='param_tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "107/107 [==============================] - 14s 133ms/step - loss: 1.3962 - accuracy: 0.8265 - val_loss: 0.2307 - val_accuracy: 0.9459\n",
      "Epoch 2/12\n",
      "107/107 [==============================] - 15s 136ms/step - loss: 0.2910 - accuracy: 0.9231 - val_loss: 0.1677 - val_accuracy: 0.9597\n",
      "Epoch 3/12\n",
      "107/107 [==============================] - 15s 139ms/step - loss: 0.1882 - accuracy: 0.9462 - val_loss: 0.1280 - val_accuracy: 0.9685\n",
      "Epoch 4/12\n",
      "107/107 [==============================] - 15s 137ms/step - loss: 0.1229 - accuracy: 0.9610 - val_loss: 0.1156 - val_accuracy: 0.9697\n",
      "Epoch 5/12\n",
      "107/107 [==============================] - 14s 135ms/step - loss: 0.0889 - accuracy: 0.9712 - val_loss: 0.1087 - val_accuracy: 0.9726\n",
      "Epoch 6/12\n",
      "107/107 [==============================] - 14s 134ms/step - loss: 0.0613 - accuracy: 0.9793 - val_loss: 0.1028 - val_accuracy: 0.9768\n",
      "Epoch 7/12\n",
      "107/107 [==============================] - 14s 133ms/step - loss: 0.0524 - accuracy: 0.9821 - val_loss: 0.1046 - val_accuracy: 0.9762\n",
      "Epoch 8/12\n",
      "107/107 [==============================] - 14s 134ms/step - loss: 0.0409 - accuracy: 0.9865 - val_loss: 0.0883 - val_accuracy: 0.9803\n",
      "Epoch 9/12\n",
      "107/107 [==============================] - 14s 133ms/step - loss: 0.0327 - accuracy: 0.9892 - val_loss: 0.0786 - val_accuracy: 0.9821\n",
      "Epoch 10/12\n",
      "107/107 [==============================] - 14s 134ms/step - loss: 0.0283 - accuracy: 0.9904 - val_loss: 0.0869 - val_accuracy: 0.9812\n",
      "Epoch 11/12\n",
      "107/107 [==============================] - 14s 135ms/step - loss: 0.0297 - accuracy: 0.9896 - val_loss: 0.0813 - val_accuracy: 0.9826\n",
      "Epoch 12/12\n",
      "107/107 [==============================] - 14s 133ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0900 - val_accuracy: 0.9806\n",
      "Test loss: 0.09002281725406647\n",
      "Test accuracy: 0.9805882573127747\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "scores['param_tanh']=score[1]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# param_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='param_sigmoid',input_shape=(32,32,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='param_sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='param_sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "107/107 [==============================] - 18s 166ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.0626 - val_accuracy: 0.9888\n",
      "Epoch 2/12\n",
      "107/107 [==============================] - 18s 169ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0641 - val_accuracy: 0.9885\n",
      "Epoch 3/12\n",
      "107/107 [==============================] - 18s 171ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0618 - val_accuracy: 0.9888\n",
      "Epoch 4/12\n",
      "107/107 [==============================] - 19s 178ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.0686 - val_accuracy: 0.9897\n",
      "Epoch 5/12\n",
      "107/107 [==============================] - 19s 175ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0626 - val_accuracy: 0.9906\n",
      "Epoch 6/12\n",
      "107/107 [==============================] - 18s 170ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.0518 - val_accuracy: 0.9912\n",
      "Epoch 7/12\n",
      "107/107 [==============================] - 18s 166ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0635 - val_accuracy: 0.9900\n",
      "Epoch 8/12\n",
      "107/107 [==============================] - 18s 165ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0611 - val_accuracy: 0.9891\n",
      "Epoch 9/12\n",
      "107/107 [==============================] - 18s 166ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0585 - val_accuracy: 0.9900\n",
      "Epoch 10/12\n",
      "107/107 [==============================] - 18s 166ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0653 - val_accuracy: 0.9894\n",
      "Epoch 11/12\n",
      "107/107 [==============================] - 18s 166ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.0612 - val_accuracy: 0.9882\n",
      "Epoch 12/12\n",
      "107/107 [==============================] - 18s 166ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.0716 - val_accuracy: 0.9882\n",
      "Test loss: 0.07156664878129959\n",
      "Test accuracy: 0.9882352948188782\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "scores['param_sigmoid']=score[1]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(32,32,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "107/107 [==============================] - 12s 113ms/step - loss: 0.6276 - accuracy: 0.7970 - val_loss: 0.1138 - val_accuracy: 0.9656\n",
      "Epoch 2/12\n",
      "107/107 [==============================] - 12s 112ms/step - loss: 0.1591 - accuracy: 0.9505 - val_loss: 0.0722 - val_accuracy: 0.9797\n",
      "Epoch 3/12\n",
      "107/107 [==============================] - 12s 115ms/step - loss: 0.0974 - accuracy: 0.9682 - val_loss: 0.0511 - val_accuracy: 0.9853\n",
      "Epoch 4/12\n",
      "107/107 [==============================] - 13s 118ms/step - loss: 0.0709 - accuracy: 0.9774 - val_loss: 0.0535 - val_accuracy: 0.9862\n",
      "Epoch 5/12\n",
      "107/107 [==============================] - 13s 118ms/step - loss: 0.0603 - accuracy: 0.9815 - val_loss: 0.0423 - val_accuracy: 0.9885\n",
      "Epoch 6/12\n",
      "107/107 [==============================] - 13s 118ms/step - loss: 0.0469 - accuracy: 0.9844 - val_loss: 0.0378 - val_accuracy: 0.9894\n",
      "Epoch 7/12\n",
      "107/107 [==============================] - 13s 118ms/step - loss: 0.0384 - accuracy: 0.9873 - val_loss: 0.0478 - val_accuracy: 0.9885\n",
      "Epoch 8/12\n",
      "107/107 [==============================] - 13s 118ms/step - loss: 0.0375 - accuracy: 0.9869 - val_loss: 0.0415 - val_accuracy: 0.9897\n",
      "Epoch 9/12\n",
      "107/107 [==============================] - 13s 118ms/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.0417 - val_accuracy: 0.9900\n",
      "Epoch 10/12\n",
      "107/107 [==============================] - 13s 117ms/step - loss: 0.0361 - accuracy: 0.9885 - val_loss: 0.0411 - val_accuracy: 0.9900\n",
      "Epoch 11/12\n",
      "107/107 [==============================] - 13s 118ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 0.0436 - val_accuracy: 0.9894\n",
      "Epoch 12/12\n",
      "107/107 [==============================] - 13s 118ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 0.0412 - val_accuracy: 0.9891\n",
      "Test loss: 0.04123209789395332\n",
      "Test accuracy: 0.9891176223754883\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "scores['Relu']=score[1]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='tanh',input_shape=(32,32,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "107/107 [==============================] - 13s 125ms/step - loss: 0.4271 - accuracy: 0.8662 - val_loss: 0.1593 - val_accuracy: 0.9503\n",
      "Epoch 2/12\n",
      "107/107 [==============================] - 13s 123ms/step - loss: 0.1545 - accuracy: 0.9535 - val_loss: 0.1041 - val_accuracy: 0.9718\n",
      "Epoch 3/12\n",
      "107/107 [==============================] - 14s 133ms/step - loss: 0.1071 - accuracy: 0.9684 - val_loss: 0.0899 - val_accuracy: 0.9729\n",
      "Epoch 4/12\n",
      "107/107 [==============================] - 14s 133ms/step - loss: 0.0744 - accuracy: 0.9795 - val_loss: 0.0834 - val_accuracy: 0.9771\n",
      "Epoch 5/12\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 0.0610 - accuracy: 0.9825 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 6/12\n",
      "107/107 [==============================] - 14s 133ms/step - loss: 0.0471 - accuracy: 0.9872 - val_loss: 0.0636 - val_accuracy: 0.9835\n",
      "Epoch 7/12\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 0.0400 - accuracy: 0.9879 - val_loss: 0.0660 - val_accuracy: 0.9812\n",
      "Epoch 8/12\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 0.0338 - accuracy: 0.9912 - val_loss: 0.0636 - val_accuracy: 0.9821\n",
      "Epoch 9/12\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.0665 - val_accuracy: 0.9835\n",
      "Epoch 10/12\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.0641 - val_accuracy: 0.9841\n",
      "Epoch 11/12\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.0715 - val_accuracy: 0.9803\n",
      "Epoch 12/12\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.0621 - val_accuracy: 0.9832\n",
      "Test loss: 0.06211266294121742\n",
      "Test accuracy: 0.9832352995872498\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "scores['tanh']=score[1]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='sigmoid',input_shape=(32,32,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "107/107 [==============================] - 13s 124ms/step - loss: 2.5305 - accuracy: 0.1011 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 2/12\n",
      "107/107 [==============================] - 13s 121ms/step - loss: 2.4143 - accuracy: 0.0975 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
      "Epoch 3/12\n",
      "107/107 [==============================] - 14s 128ms/step - loss: 2.3670 - accuracy: 0.1018 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
      "Epoch 4/12\n",
      "107/107 [==============================] - 13s 124ms/step - loss: 2.3428 - accuracy: 0.1009 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
      "Epoch 5/12\n",
      "107/107 [==============================] - 13s 125ms/step - loss: 2.3304 - accuracy: 0.0975 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
      "Epoch 6/12\n",
      "107/107 [==============================] - 13s 124ms/step - loss: 2.3183 - accuracy: 0.1004 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 7/12\n",
      "107/107 [==============================] - 14s 128ms/step - loss: 2.3127 - accuracy: 0.1005 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
      "Epoch 8/12\n",
      "107/107 [==============================] - 14s 128ms/step - loss: 2.3088 - accuracy: 0.1043 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 9/12\n",
      "107/107 [==============================] - 14s 127ms/step - loss: 2.3081 - accuracy: 0.0992 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 10/12\n",
      "107/107 [==============================] - 13s 124ms/step - loss: 2.3070 - accuracy: 0.0978 - val_loss: 2.3052 - val_accuracy: 0.1000\n",
      "Epoch 11/12\n",
      "107/107 [==============================] - 13s 124ms/step - loss: 2.3073 - accuracy: 0.0994 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 12/12\n",
      "107/107 [==============================] - 14s 126ms/step - loss: 2.3067 - accuracy: 0.0948 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Test loss: 2.3036131858825684\n",
      "Test accuracy: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "scores['sigmoid']=score[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Relu_moid': 98.1176495552063,\n",
       " 'param_tanh': 98.05882573127747,\n",
       " 'param_sigmoid': 98.82352948188782,\n",
       " 'Relu': 98.91176223754883,\n",
       " 'tanh': 98.32352995872498,\n",
       " 'sigmoid': 10.000000149011612}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
